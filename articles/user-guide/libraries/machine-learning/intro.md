---
title: Biblioteka dla kwantowego uczenia maszynowego
description: Dowiedz się, jak uczenie maszynowe jest używane w systemach Quantum
author: alexeib2
ms.author: alexeib
ms.date: 11/22/2019
ms.topic: article
uid: microsoft.quantum.libraries.machine-learning.intro
no-loc:
- Q#
- $$v
ms.openlocfilehash: 9f7f892fb2b76432942c86163497c22f0c73d51f
ms.sourcegitcommit: 9b0d1ffc8752334bd6145457a826505cc31fa27a
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 09/21/2020
ms.locfileid: "90833799"
---
# <a name="introduction-to-quantum-machine-learning"></a><span data-ttu-id="ef2cf-103">Wprowadzenie do Machine Learning Quantum</span><span class="sxs-lookup"><span data-stu-id="ef2cf-103">Introduction to Quantum Machine Learning</span></span>

## <a name="framework-and-goals"></a><span data-ttu-id="ef2cf-104">Struktura i cele</span><span class="sxs-lookup"><span data-stu-id="ef2cf-104">Framework and goals</span></span>

<span data-ttu-id="ef2cf-105">Kodowanie i przetwarzanie informacji przy użyciu Quantum jest zaawansowaną alternatywą dla klasycznego klasyfikatora funkcji uczenia maszynowego.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-105">Quantum encoding and processing of information is a powerful alternative to classical machine learning Quantum classifiers.</span></span> <span data-ttu-id="ef2cf-106">W szczególności pozwala nam kodować dane w rejestrach Quantum, które są zwięzłe względem liczby funkcji, systematycznie wykorzystuj Entanglement Quantum jako zasób obliczeniowy i wykorzystując pomiar Quantum dla wnioskowania klas.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-106">In particular, it allows us to encode data in quantum registers that are concise relative to the number of features, systematically employing quantum entanglement as computational resource and employing quantum measurement for class inference.</span></span>
<span data-ttu-id="ef2cf-107">Klasyfikator Quantum oparty na obwodzie to stosunkowo proste rozwiązanie Quantum, które łączy dane kodowania z szybkim obwodem Quantum Entangling/disentangling, a następnie pomiarem do wywnioskowania etykiet klas próbek danych.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-107">Circuit centric quantum classifier is a relatively simple quantum solution that combines data encoding with a rapidly entangling/disentangling quantum circuit followed by measurement to infer class labels of data samples.</span></span>
<span data-ttu-id="ef2cf-108">Celem jest zapewnienie klasycznej charakterystyki i magazynowania obwodów podmiotu, a także hybrydowego procesu Quantum/klasycznego szkolenia parametrów obwodu nawet dla bardzo dużych miejsc funkcji.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-108">The goal is to ensure classical characterization and storage of subject circuits, as well as hybrid quantum/classical training of the circuit parameters even for extremely large feature spaces.</span></span>

## <a name="classifier-architecture"></a><span data-ttu-id="ef2cf-109">Architektura klasyfikatora</span><span class="sxs-lookup"><span data-stu-id="ef2cf-109">Classifier architecture</span></span>

<span data-ttu-id="ef2cf-110">Klasyfikacja to nadzorowane zadanie uczenia maszynowego, w którym celem jest wywnioskowanie etykiet klas $ \{ y_1, y_2, \ldots, y_d \} $ niektórych próbek danych.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-110">Classification is a supervised machine learning task, where the goal is to infer class labels $\{y_1,y_2,\ldots,y_d\}$ of certain data samples.</span></span> <span data-ttu-id="ef2cf-111">"Zestaw danych szkoleniowych" to kolekcja przykładów $ \mathcal{D} = \{ (x, y)} $ ze znanymi wstępnie przypisanymi etykietami.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-111">The "training data set" is a collection of samples $\mathcal{D}=\{(x,y)}$ with known pre-assigned labels.</span></span> <span data-ttu-id="ef2cf-112">Tutaj $x $ to przykład danych, a $y $ to jego znana etykieta o nazwie "etykieta szkoleniowa".</span><span class="sxs-lookup"><span data-stu-id="ef2cf-112">Here $x$ is a data sample and $y$ is its known label called "training label".</span></span>
<span data-ttu-id="ef2cf-113">Podobnie jak w przypadku tradycyjnych metod, klasyfikacja Quantum składa się z trzech kroków:</span><span class="sxs-lookup"><span data-stu-id="ef2cf-113">Somewhat similar to traditional methods, quantum classification consists of three steps:</span></span>
- <span data-ttu-id="ef2cf-114">kodowanie danych</span><span class="sxs-lookup"><span data-stu-id="ef2cf-114">data encoding</span></span>
- <span data-ttu-id="ef2cf-115">Przygotowanie stanu klasyfikatora</span><span class="sxs-lookup"><span data-stu-id="ef2cf-115">preparation of a classifier state</span></span>
- <span data-ttu-id="ef2cf-116">pomiar ze względu na probabilistyczne charakter pomiaru, te trzy kroki muszą być powtórzone wielokrotnie.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-116">measurement Due to the probabilistic nature of the measurement, these three steps must be repeated multiple times.</span></span> <span data-ttu-id="ef2cf-117">Zarówno kodowanie, jak i obliczenia stanu klasyfikatora są wykonywane za pomocą *obwodów Quantum*.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-117">Both the encoding and the computing of the classifier state are done by means of *quantum circuits*.</span></span> <span data-ttu-id="ef2cf-118">Gdy obwód kodowania jest zwykle oparty na danych i bez parametrów, obwód klasyfikatora zawiera wystarczającą zestaw parametrów, które można uzyskać.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-118">While the encoding circuit is usually data-driven and parameter-free, the classifier circuit contains a sufficient set of learnable parameters.</span></span> 

<span data-ttu-id="ef2cf-119">W proponowanym rozwiązaniu obwód klasyfikatora składa się z rotacji jednoqubitowych i trójwymiarowych rotacji z dwoma qubitami.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-119">In the proposed solution the classifier circuit is composed of single-qubit rotations and two-qubit controlled rotations.</span></span> <span data-ttu-id="ef2cf-120">W tym miejscu są to kąty obrotu.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-120">The learnable parameters here are the rotation angles.</span></span> <span data-ttu-id="ef2cf-121">Bramy rotacji i kontrolowanej rotacji są znane jako *uniwersalne* dla obliczeń Quantum, co oznacza, że każda macierz masy jednostkowej może być rozłożone na wystarczająco długi obwód składający się z takich bram.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-121">The rotation and controlled rotation gates are known to be *universal* for quantum computation, which means that any unitary weight matrix can be decomposed into a long enough circuit consisting of such gates.</span></span>

<span data-ttu-id="ef2cf-122">W proponowanej wersji obsługiwana jest tylko jedna obwód, po której następuje szacowanie o pojedynczej częstotliwości.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-122">In the proposed version, only one circuit followed by a single frequency estimation is supported.</span></span>
<span data-ttu-id="ef2cf-123">W takim przypadku rozwiązanie jest analogową usługą Quantum dla maszyny wektorowej pomocy technicznej z niewielką ilością jądra wielostopniowego.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-123">Thus, the solution is a quantum analog of a support vector machine with a low-degree polynomial kernel.</span></span>

![Multilayer Perceptron a klasyfikator skoncentrowany obwodu](~/media/DLvsQCC.png)

<span data-ttu-id="ef2cf-125">Prosty projekt klasyfikatora Quantum można porównać do tradycyjnego rozwiązania do obsługi maszyn wektorowych (SVM).</span><span class="sxs-lookup"><span data-stu-id="ef2cf-125">A simple quantum classifier design can be compared to a traditional support vector machine (SVM) solution.</span></span> <span data-ttu-id="ef2cf-126">Wnioskowanie dla przykładu danych $x $ w przypadku SVM jest wykonywane przy użyciu optymalnego formularza jądra $ \sum \ alpha_j k (x_j, x) $, gdzie $k $ jest pewną funkcją jądra.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-126">The inference for a data sample $x$ in case of SVM is done using an optimal kernel form $\sum \alpha_j  k(x_j,x)$ where $k$ is a certain kernel function.</span></span>

<span data-ttu-id="ef2cf-127">Z kolei klasyfikator Quantum używa predykcyjności $p (y │ x, U (\theta)) = 〈 U (\theta) x | M | U (\theta) x 〉 $, który jest podobny w duchu, ale technicznie inny.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-127">By contrast, a quantum classifier uses the predictor $p(y│x,U(\theta))=〈U(\theta)x|M|U(\theta)x〉$, which is similar in spirit but technically quite different.</span></span> <span data-ttu-id="ef2cf-128">W tym przypadku, gdy używane jest proste kodowanie amplitudy, $p (y │ x, U (\theta)) $ jest postacią kwadratową w amplitudach $x $, ale współczynniki tego formularza nie są już niezależne. Zamiast tego są one agregowane z elementów macierzy obwodu $U (\theta) $, które zwykle mają znacznie mniej bardziej poznanie parametry $ \theta $ niż wymiar wektora $x $.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-128">Thus, when a straightforward amplitude encoding is used,  $p(y│x,U(\theta))$ is a quadratic form in the amplitudes of $x$, but the coefficients of this form are no longer learned independently; they are instead aggregated from the matrix elements of the circuit $U(\theta)$, which typically has significantly fewer learnable parameters $\theta$ than the dimension of the vector $x$.</span></span> <span data-ttu-id="ef2cf-129">Stopień wielomianu $p (y │ x, U (\theta)) $ w oryginalnych funkcjach można zwiększyć do wartości $2 ^ l $ przy użyciu kodowania produktu Quantum na $l $ kopie $x $.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-129">The polynomial degree of $p(y│x,U(\theta))$ in the original features can be increased to $2^l$ by using a quantum product encoding on $l$ copies of $x$.</span></span>

<span data-ttu-id="ef2cf-130">Nasza architektura analizuje stosunkowo płytki obwodów, co w związku z tym musi być *szybko Entangling* w celu przechwycenia wszystkich korelacji między funkcjami danych we wszystkich zakresach.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-130">Our architecture explores relatively shallow circuits, which therefore must be *rapidly entangling* in order to capture all the correlations between the data features at all ranges.</span></span> <span data-ttu-id="ef2cf-131">Przykład najbardziej przydatnego, szybkiego składnika obwodu Entangling pokazano na poniższej ilustracji.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-131">An example of the most useful rapidly entangling circuit component is shown on figure below.</span></span> <span data-ttu-id="ef2cf-132">Mimo że obwód z tą geometrią składa się tylko z bram o $3 n + 1 $, macierz wagi jednostki, która jest obliczana, zapewnia znaczącą komunikację krzyżową między funkcjami $2 ^ n $.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-132">Even though a circuit with this geometry consists of only $3 n+1$ gates, the unitary weight matrix that it computes ensures significant cross-talk between $2^n$ features.</span></span>

![Szybko Entangling obwód Quantum na 5 qubits (z dwiema warstwami cyklicznymi).](~/media/5-qubit-qccc.png)

<span data-ttu-id="ef2cf-134">Obwód w powyższym przykładzie składa się z 6 G_1 bram qubit, \ldots, G_5; G_ {16} ) $ i 10 2-qubits bramy $ (G_6, \ldots, G_ {15} ) $.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-134">The circuit in the above example consists of 6 single-qubit gates $(G_1,\ldots,G_5; G_{16})$ and 10 two-qubits gates $(G_6,\ldots,G_{15})$.</span></span> <span data-ttu-id="ef2cf-135">Przy założeniu, że każda Brama jest zdefiniowana za pomocą jednego z parametrów, który ma 16 parametrów, podczas gdy wymiar 5-qubit Hilbert jest 32.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-135">Assuming that each of the gates is defined with one learnable parameter we have 16 learnable parameters, while the dimension of the 5-qubit Hilbert space is 32.</span></span> <span data-ttu-id="ef2cf-136">Taka geometria obwodu może być w łatwy sposób uogólniony do dowolnego $ngo rejestru $-qubit, gdy $n $ jest nieparzysta, co generuje obwody z $3 n + 1 $ parametrów dla przestrzeni funkcji $2 ^ n $-wymiarową.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-136">Such circuit geometry can be easily generalized to any $n$-qubit register, when $n$ is odd, yielding circuits with $3 n+1$ parameters for $2^n$-dimensional feature space.</span></span>

## <a name="classifier-training-as-a-supervised-learning-task"></a><span data-ttu-id="ef2cf-137">Szkolenie klasyfikatora jako nadzorowane zadanie uczenia się</span><span class="sxs-lookup"><span data-stu-id="ef2cf-137">Classifier training as a supervised learning task</span></span>

<span data-ttu-id="ef2cf-138">Szkolenie modelu klasyfikatora polega na znalezieniu optymalnych wartości parametrów operacyjnych, takich jak maksymalizacja średniego prawdopodobieństwa wywnioskowania prawidłowych etykiet szkoleniowych na przykładach szkoleniowych.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-138">Training of a classifier model involves finding optimal values of its operational parameters, such that they maximize the average likelihood of inferring the correct training labels across the training samples.</span></span>
<span data-ttu-id="ef2cf-139">W tym scenariuszu dotyczymy tylko wypróbujemy z klasyfikacją dwóch poziomów, np. $d = $2 i tylko dwie klasy z etykietami $y _1, y_2 $.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-139">Here, we concern ourselves with two level classification only, i.e. the case of $d=2$ and only two classes with the labels $y_1,y_2$.</span></span>

> [!NOTE]
> <span data-ttu-id="ef2cf-140">Zasadnym sposobem uogólniania metod do dowolnej liczby klas jest zamienienie qubits z qudits, tj. jednostkami Quantum z $d $, i pomiaru dwukierunkowego z $dnym pomiarem.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-140">A principled way of generalizing our methods to arbitrary number of classes is to replace qubits with qudits, i.e. quantum units with $d$ basis states, and the two-way measurement with $d$-way measurement.</span></span>

### <a name="likelihood-as-the-training-goal"></a><span data-ttu-id="ef2cf-141">Prawdopodobieństwo, że cel szkolenia</span><span class="sxs-lookup"><span data-stu-id="ef2cf-141">Likelihood as the training goal</span></span>

<span data-ttu-id="ef2cf-142">Uwzględniając $Uy obwód Quantum, gdzie $ \theta $ jest wektorem parametrów, i wskazując końcowy pomiar przez $M $, średnie prawdopodobieństwo poprawnego wnioskowania etykiety to $ $ \begin{align} \mathcal{L} (\theta) = \frac {1} {| \mathcal{D} |} \left (\ sum_ {(x, y_1) \In\mathcal{D}} P (M = y_1 | U (\theta) x) + \ sum_ {(x, y_2) \in\mathcal{D}} P (M = y_2 | U (\theta) x) \right) \end{align} $ $, gdzie $P (M = y | z) $ jest prawdopodobieństwem mierzenia $y $ w stanie Quantum $z $.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-142">Given a learnable quantum circuit $U(\theta)$, where $\theta$ is a vector of parameters, and denoting the final measurement by $M$, the average likelihood of the correct label inference is $$ \begin{align} \mathcal{L}(\theta)=\frac{1}{|\mathcal{D}|} \left( \sum_{(x,y_1)\in\mathcal{D}} P(M=y_1|U(\theta) x) + \sum_{(x,y_2)\in\mathcal{D}} P(M=y_2|U(\theta) x)\right) \end{align} $$ where $P(M=y|z)$ is the probability of measuring $y$ in quantum state $z$.</span></span>
<span data-ttu-id="ef2cf-143">W tym miejscu wystarczy zrozumieć, że funkcja prawdopodobieństwo $ \mathcal{L} (\theta) $ jest gładka w $ \theta $, a jej pochodna w dowolnym $ \ theta_j $ może zostać obliczona w ramach tego samego protokołu Quantum, co jest używane do obliczania prawdopodobieństwa samego działania.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-143">Here, it suffices to understand that the likelihood function $\mathcal{L}(\theta)$ is smooth in $\theta$ and its derivative in any $\theta_j$ can be computed by essentially the same quantum protocol as used for computing the likelihood function itself.</span></span> <span data-ttu-id="ef2cf-144">Pozwala to na optymalizację $ \mathcal{L} (\theta) $ według gradientu.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-144">This allows for optimizing the $\mathcal{L}(\theta)$ by gradient descent.</span></span>

### <a name="classifier-bias-and-training-score"></a><span data-ttu-id="ef2cf-145">Ocena odchylenia i szkolenia klasyfikatora</span><span class="sxs-lookup"><span data-stu-id="ef2cf-145">Classifier bias and training score</span></span>

<span data-ttu-id="ef2cf-146">Uwzględniając pewne pośrednie (lub końcowe) wartości parametrów w $ \theta $, musimy zidentyfikować jedną rzeczywistą wartość $b $ wie jako *bias klasyfikatora* , aby wykonać wnioskowanie.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-146">Given some intermediate (or final) values of the parameters in $\theta$, we need to identify a single real value $b$ know as *classifier bias* to do the inference.</span></span> <span data-ttu-id="ef2cf-147">Reguła wnioskowania o etykiecie działa w następujący sposób:</span><span class="sxs-lookup"><span data-stu-id="ef2cf-147">The label inference rule works as follows:</span></span> 
- <span data-ttu-id="ef2cf-148">Przykładem $x $ jest przypisana etykieta $y _2 $ if i tylko wtedy, gdy $P (M = y_2 | U (\theta) x) + b > $0,5 (RULE1) (w przeciwnym razie jest przypisana etykieta $y _1 $)</span><span class="sxs-lookup"><span data-stu-id="ef2cf-148">A sample $x$ is assigned label $y_2$ if and only if $P(M=y_2|U(\theta) x) + b > 0.5$  (RULE1) (otherwise it is assigned label $y_1$)</span></span>

<span data-ttu-id="ef2cf-149">Jasno $b $ musi znajdować się w interwale $ (-0,5, + 0,5) $, aby mieć znaczenie.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-149">Clearly $b$ must be in the interval $(-0.5,+0.5)$ to be meaningful.</span></span>

<span data-ttu-id="ef2cf-150">Przypadek szkoleniowy $ (x, y) \In \mathcal{D} $ jest uznawany za nieprawidłową *klasyfikację* na podstawie odchylenia $b $, jeśli etykieta wnioskowana dla $x $ AS na RULE1 jest w rzeczywistości różna od $y $.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-150">A training case $(x,y) \in \mathcal{D}$ is considered a *misclassification* given the bias $b$ if the label inferred for $x$ as per RULE1 is actually different from $y$.</span></span> <span data-ttu-id="ef2cf-151">Ogólna liczba *nieocenionych klasyfikacji to wynik szkoleniowy* klasyfikatora z uwzględnieniem odchylenia $b $.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-151">The overall number of misclassifications is the *training score* of the classifier given the bias $b$.</span></span> <span data-ttu-id="ef2cf-152">*Optymalna* wartość klasyfikatora $b $ minimalizuje wynik szkolenia.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-152">The *optimal* classifier bias $b$ minimizes the training score.</span></span> <span data-ttu-id="ef2cf-153">Jest to łatwe do sprawdzenia, czy z góry obliczone oszacowania prawdopodobieństwa $ \{ P (M = y_2 | U (\theta) x) | (x, \*) \in\mathcal{D} \} $, optymalna wartość klasyfikatora może być znaleziona przez wyszukiwanie binarne w interwale $ (-0,5, + 0,5) $ przez utworzenie maksymalnie $ \ Log_2 (| \mathcal{D} |) $ kroki.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-153">It is easy to see that, given the precomputed probability estimates $\{ P(M=y_2|U(\theta) x) | (x,\*)\in\mathcal{D} \}$, the optimal classifier bias can be found by binary search in interval $(-0.5,+0.5)$ by making at most $\log_2(|\mathcal{D}|)$ steps.</span></span>

### <a name="reference"></a><span data-ttu-id="ef2cf-154">Dokumentacja</span><span class="sxs-lookup"><span data-stu-id="ef2cf-154">Reference</span></span>

<span data-ttu-id="ef2cf-155">Te informacje powinny być wystarczające, aby rozpocząć odtwarzanie kodu.</span><span class="sxs-lookup"><span data-stu-id="ef2cf-155">This information should be enough to start playing with the code.</span></span> <span data-ttu-id="ef2cf-156">Jeśli jednak chcesz dowiedzieć się więcej na temat tego modelu, zapoznaj się z oryginalną propozycją: [ *"skoncentrowane na obwodach klasyfikatory Quantum", Maria Schuld, Alex Bocharov, krysta Svore i Nathana Wiebe*](https://arxiv.org/abs/1804.00633)</span><span class="sxs-lookup"><span data-stu-id="ef2cf-156">However, if you want to learn more about this model, please read the original proposal: [*'Circuit-centric quantum classifiers', Maria Schuld, Alex Bocharov, Krysta Svore and Nathan Wiebe*](https://arxiv.org/abs/1804.00633)</span></span>

<span data-ttu-id="ef2cf-157">Oprócz przykładu kodu, który będzie widoczny w następnych krokach, można również rozpocząć Eksplorowanie klasyfikacji Quantum w [tym samouczku](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification)</span><span class="sxs-lookup"><span data-stu-id="ef2cf-157">In addition to the code sample you will see in the next steps, you can also start exploring quantum classification in [this tutorial](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification)</span></span> 
